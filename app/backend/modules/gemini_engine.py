import os
import json
import google.generativeai as genai
from modules.prophet_engine import get_kpis, predict_serie

# ==========================
# âš™ï¸ ConfiguraciÃ³n de Gemini
# ==========================

print("ðŸ§  [INIT] Cargando mÃ³dulo gemini_engine desde:", __file__)

GEMINI_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_KEY:
    print("âš ï¸  [CONFIG] Falta GEMINI_API_KEY en entorno")
else:
    print("âœ… [CONFIG] GEMINI_API_KEY detectada:", GEMINI_KEY[:8] + "********")
    genai.configure(api_key=GEMINI_KEY)

# Usa el modelo correcto (sin 'models/')
MODEL_NAME = "gemini-2.5-pro"
print(f"ðŸ§© [MODEL] Intentando inicializar modelo: {MODEL_NAME}")

try:
    MODEL = genai.GenerativeModel(MODEL_NAME)
    print(f"âœ… [MODEL] Modelo '{MODEL_NAME}' inicializado correctamente.")
except Exception as e:
    print(f"âŒ [MODEL INIT ERROR] No se pudo inicializar el modelo '{MODEL_NAME}': {e}")
    MODEL = None

# ==========================
# ðŸ” VerificaciÃ³n inicial (conexiÃ³n de prueba)
# ==========================
if MODEL:
    try:
        print("ðŸ§ª [TEST] Enviando prueba a Gemini...")
        test_resp = MODEL.generate_content("Hola, Gemini. Prueba de conexiÃ³n del servidor financiero.")
        if test_resp and hasattr(test_resp, "text"):
            print("âœ… [TEST] ConexiÃ³n con Gemini OK. Respuesta:", test_resp.text[:80], "...")
        else:
            print("âš ï¸ [TEST] Gemini respondiÃ³ sin texto. Revisa tu cuota o el modelo.")
    except Exception as e:
        print(f"ðŸš¨ [Gemini Startup Error] {e}")
else:
    print("âš ï¸ [INIT] No se pudo crear instancia de Gemini; modelo es None.")

# ==========================
# ðŸ§  FunciÃ³n principal
# ==========================
def ask_gemini(question: str) -> str:
    """Genera una respuesta en contexto financiero usando Gemini + Prophet."""
    print(f"\nðŸ’¬ [ASK] Recibida pregunta: {question}")

    kpis_macro = get_kpis()
    forecast_hint = ""

    # --------------------------
    # ðŸ”Ž Intentar incluir contexto de predicciones
    # --------------------------
    try:
        if "tipo de cambio" in question.lower():
            preds = predict_serie("tipo_cambio_fix")
            if isinstance(preds, list) and preds:
                last = preds[-1]
                forecast_hint = f"El tipo de cambio se estima en {last['yhat']:.2f} MXN/USD para {last['ds']}."
        elif "tasa" in question.lower():
            preds = predict_serie("tasa_referencia")
            if isinstance(preds, list) and preds:
                last = preds[-1]
                forecast_hint = f"La tasa de referencia podrÃ­a ser {last['yhat']:.2f}% para {last['ds']}."
        elif "ipc" in question.lower():
            preds = predict_serie("ipc_bmv")
            if isinstance(preds, list) and preds:
                last = preds[-1]
                forecast_hint = f"El IPC de la Bolsa Mexicana se estima en {last['yhat']:.2f} puntos para {last['ds']}."
    except Exception as e:
        print(f"[Gemini Context Error] {e}")

    # --------------------------
    # ðŸ“‹ Crear contexto para Gemini
    # --------------------------
    context = f"""
    Contexto macroeconÃ³mico:
    {json.dumps(kpis_macro, indent=2, ensure_ascii=False)}

    {forecast_hint if forecast_hint else "Sin pronÃ³sticos recientes disponibles."}
Instrucciones:
    - Responde en espaÃ±ol con base exclusivamente en los datos proporcionados por Prophet.
    - No inventes cifras adicionales ni amplÃ­es rangos.
    - Si existe un valor estimado (`forecast_hint`), utilÃ­zalo como el pronÃ³stico principal.
    - Explica brevemente el razonamiento financiero detrÃ¡s, pero sin modificar la cifra estimada.
    - Usa tono de asesor financiero profesional.
    - MantÃ©n la respuesta concisa (mÃ¡ximo 3 pÃ¡rrafos cortos).

    """

    # --------------------------
    # ðŸ§  Llamar a Gemini
    # --------------------------
    if MODEL is None:
        print("ðŸš¨ [ERROR] No hay modelo Gemini inicializado. Revisa configuraciÃ³n.")
        return "Error interno: Gemini no estÃ¡ configurado correctamente."

    try:
        print("ðŸ“¤ [Gemini Request] Enviando prompt al modelo...")
        response = MODEL.generate_content(context + "\n\nPregunta: " + question)
        print("ðŸ“¥ [Gemini Response] Respuesta recibida correctamente.")
        print("ðŸ§¾ [Gemini Output] Primeras lÃ­neas de respuesta:\n", response.text[:200])
        print(f"[DEBUG] forecast_hint usado: {forecast_hint}")
        return response.text.strip()
    except Exception as e:
        print(f"ðŸš¨ [Gemini Error] {e}")
        return "Lo siento, no pude generar una respuesta en este momento."
